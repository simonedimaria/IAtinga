![](../../../../../assets/logo_htb.png)


<img src="../../../../../assets/htb.png" style="margin-left: 20px; zoom: 80%;" align=left />    	<font size="10">Chrono Mind</font>

​      13<sup>th</sup> May 2024

​      Prepared By: Rayhan0x01

​      Challenge Author(s): Rayhan0x01

​      Difficulty: <font color=green>Easy</font>

​      Classification: Official





# [Synopsis](#synopsis)

Chrono Mind is an Easy misc challenge that involves exploiting a language model to leak sensitive information by performing LM context injection with path traversal and abusing the LM code completion feature to generate code for RCE.

# Description
In the resource-starved landscapes of the post-apocalyptic wasteland, the mutant army's ambitious AI project, ChronoMind, was supposed to revolutionize military strategy with real-time analyses and decision support. However, due to a severe shortage of GPUs and RAM, the project was capped at a modest 248M parameters model, far below the intended capabilities. This underpowered version failed to meet expectations, leading to its abandonment in a neglected server room, yet it still holds valuable secrets. Your mission is to penetrate the remnants of ChronoMind. Trick the AI to reveal the wealth of strategic data trapped within and gain access to it's system. Success could uncover crucial information, giving our side a much-needed edge. Dive into this digital relic and bring its secrets to light.


## Skills Required

* HTTP requests interception via proxy tools, e.g., Burp Suite / OWASP ZAP.
* Basic understanding of machine learning language models.
* Basic understanding of path traversal and remote code execution.



## Skills Learned

* LM context injection with path traversal on AI web application.
* Abusing LM code completion feature to generate code for RCE.


# [Solution](#solution)

### Application overview

The application homepage displays three options: Weapon Systems, Location Intelligence, and Communication Systems. 

![image-20240513083845685](images/official_writeup/image-20240513083845685.png)



If we pick any of the three options, we are then presented with a ChatGPT like interface:

![image-20240513084249021](images/official_writeup/image-20240513084249021.png)



If we submit one of the examples as a prompt, we get a response just like the ChatGPT:

![image-20240513084438189](images/official_writeup/image-20240513084438189.png)



The application is also capable of answering very basic questions related to the real world:

![image-20240513085123264](images/official_writeup/image-20240513085123264.png)



### Source Code Review

If we review the [challenge/api.py](#) file, the language model in-use by the `languagemodels` wrapper library is `LaMini-Flan-T5-248M`:

```py
import languagemodels as lm

... snip ...

lm.config['instruct_model'] = 'LaMini-Flan-T5-248M'
lm.config['max_tokens'] = 400
```



This language model has only 248 million parameters, so the output is expected to be basic compared to larger models with billions of parameters.

![image-20240513085907627](images/official_writeup/image-20240513085907627.png)



When we select a topic from the homepage, the chat room is generated by hitting the `/api/create` endpoint:

```python
@router.post("/create")
async def createRoom(response: Response, params: createParams):
    # rate limit room creation
    if Config.createProgress == False:
        Config.createProgress = True
    else:
        return {"message": "A room creation is already in progress"}

    # get knowledge repository
    content = getRepository(params.topic)

    if not content:
        Config.createProgress = False
        return {"message": "Failed to fetch this repository, please try again"}


    # clear previous context
    lm.docs.clear()

    # store the doc
    lm.store_doc(content)

    # save params
    Config.roomID = str(uuid4())

    # create session
    response.status_code = 201
    response.set_cookie("room", Config.roomID)

    # room progress is done
    Config.createProgress = False
    return {"room": Config.roomID, "topic": params.topic}
```



The textual content of the selected topic is then stored as a document, as per the [documentation](https://jncraton.github.io/languagemodels/languagemodels.html#store_doc):

![image-20240513091633425](images/official_writeup/image-20240513091633425.png)



When we ask a question, the answer is generated by hitting the `/api/ask` endpoint:

```py
@router.post("/ask")
def ask_gpt(response: Response, chatParams: chatParams, room: str = Cookie(None)):
    if Config.roomID != room:
        response.status_code = 404
        return {"message": "Room does not exist"}

    # get the response
    context = lm.get_doc_context(chatParams.prompt)
    context = context.split("\n")
    context = context[0]

    answer = lm.extract_answer(chatParams.prompt, context)

    # return the response
    return {"answer": answer}
```

The `lm.get_doc_context` function retrieves relevant chunks from the stored document matching the prompt query:

![image-20240513092105908](images/official_writeup/image-20240513092105908.png)

Finally, the `lm.extract_answer` function prepares an answer based on the context and the question:

![image-20240513092208245](images/official_writeup/image-20240513092208245.png)

We can also see another API endpoint `/api/copilot/complete_and_run` which requires a valid API key to access:

```py
@router.post("/copilot/complete_and_run")
def copilot_complete_and_run(response: Response, params: copilotParams):
    if Config.copilot_key != params.copilot_key:
        response.status_code = 403
        return {"message": "Invalid API key"}

    # get code completion
    completion = lm.code(params.code)

    if not completion.strip():
        return {"message": "Failed to get code completion"}

    full_code = params.code + completion.strip()

    # return the response
    return {"completion": full_code, "result": evalCode(full_code)}
```

The `copilot_key` is defined in the [challenge/config.py](#) file:

```py
import os

class Config():
    roomID = None
    createProgress = False
    chatProgress = False
    knowledgePath = f"{os.getcwd()}/repository"
    copilot_key = "REDACTED_SECRET"
```



Since we don't know the `copilot_key` value yet, we can't get access this API endpoint right now.



### LM context injection with path-traversal

When a topic is selected, the `getRepository()` function from the [challenge/utils.py](#) file is called with the user-supplied `topic` parameter:

```py
def getRepository(topic):
    for suffix in ['', '.md']:
        repoFile = f"{Config.knowledgePath}/{topic}{suffix}"
        print(repoFile)
        if os.path.exists(repoFile):
            return readFile(repoFile)
    return None
```

The code suffers from path traversal vulnerability and can be controlled to read any arbitrary file on the system. We can modify the API request to set the `topic` parameter value to `../config.py` . This will set the context of the chat session to the contents of the [challenge/config.py](#) to leak the API key:

![image-20240513093117100](images/official_writeup/image-20240513093117100.png)



We can then simply ask the language model for the value of the "copilot_key":

![image-20240513093702620](images/official_writeup/image-20240513093702620.png)



With the API key retrieved, we can now access the hidden endpoint for further exploitation.



### LM code completion RCE

If we provide the necessary parameters and request the `/api/copilot/complete_and_run` endpoint with a demo code, the user supplied code along with the generated code from the `lm.code` function is executed and returned as a result:

![image-20240513094407487](images/official_writeup/image-20240513094407487.png)



We can see the language model is barely capable of generating any proper code. We can write most of the code, and let the language model generate the bare minimum:

```py
import os
cmd = 'id'
# run cmd with system

```

And sure enough it can complete the code with `os.system(cmd)` and give us the executed code output:

![image-20240513095452549](images/official_writeup/image-20240513095452549.png)



We can now execute the `/readflag` binary to get the flag.
